{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import uuid\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as FT\n",
    "from functools import partial\n",
    "from torch import nn\n",
    "from dataset import CocoDataset\n",
    "from utils   import *\n",
    "from model   import *\n",
    "from metric  import *\n",
    "from loss    import *\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  5 21:39:56 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 660M    Off  | 00000000:01:00.0 N/A |                  N/A |\n",
      "| N/A   44C    P8    N/A /  N/A |    359MiB /   471MiB |     N/A      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:0B:00.0 Off |                  N/A |\n",
      "| 23%   24C    P8     8W / 250W |     13MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Data transformations, dataset, & dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.54s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# define the sequence of transformations to apply to each image sample \n",
    "img_sz = 300\n",
    "basic_tfs = [PhotometricDistort(1.),\n",
    "             Flip(0.5),\n",
    "             ImageToTensor(), CategoryToTensor(), BoxToTensor(),\n",
    "             Zoomout(0.5, max_scale=2.5),\n",
    "             Normalize(), \n",
    "             Resize((img_sz, img_sz))]\n",
    "tfms = transforms.Compose(basic_tfs)\n",
    "\n",
    "# instantiate the dataset object\n",
    "ds = CocoDataset(data_dir='./', dataset='val2017', anno_type='instances', transforms=tfms)\n",
    "\n",
    "# create dataloader\n",
    "BS = 8\n",
    "dl = DataLoader(ds, batch_size=BS, shuffle=True,\n",
    "                collate_fn=partial(ds.collate_fn, img_resized=True)) # img_resized=true to indicate all image samples have been resized to same shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b297409d7c40a3a92beb7348ceb72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:81: UserWarning: \n",
      "    Found GPU1 GeForce GTX 660M which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n",
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:104: UserWarning: \n",
      "GeForce GTX 660M with CUDA capability sm_30 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_52 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 compute_86.\n",
      "If you want to use the GeForce GTX 660M GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "# create the SSD model\n",
    "ssd = SSD300(len(ds.id2cat), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-loss criteria\n",
    "criterion = MultiBoxLoss(300, ssd.prior_boxes, threshold=0.5, neg_pos_ratio=3, alpha=1., device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = mAP(ssd.n_classes, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(object):\n",
    "    \"\"\"\n",
    "    Keeps track of most recent, average, sum, and count of a metric.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=None):\n",
    "        self.reset()\n",
    "        self.name = name\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def __call__(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradient(optimizer, grad_clip):\n",
    "    \"\"\"\n",
    "    Clips gradients computed during backpropagation to avoid explosion of gradients.\n",
    "    :param optimizer: optimizer with the gradients to be clipped\n",
    "    :param grad_clip: clip value\n",
    "    \"\"\"\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group['params']:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.clamp_(-grad_clip, grad_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp():\n",
    "    \n",
    "    def __init__(self, dataloader, model, criterion, name=None, desc=None, verbose=None, device=None):\n",
    "        if device is None:\n",
    "            self.device = \"cpu\"\n",
    "        else:\n",
    "            self.device = device\n",
    "        # meta fields\n",
    "        self.name = name if name is not None else \"model\"\n",
    "        self.desc = desc if desc is not None else \"...\"\n",
    "        # dataloader, model, criterion; put to appropriate device\n",
    "        self.dl = dataloader\n",
    "        self.bs = dataloader.batch_size\n",
    "        self.m = model.to(self.device)\n",
    "        self.criterion = criterion.to(self.device)\n",
    "        self.verbose = verbose\n",
    "\n",
    "        \n",
    "    def setup(self):\n",
    "        # init training process params\n",
    "        self.epoch = 0        \n",
    "        # create directory to hold experiment artifacts\n",
    "        import os\n",
    "        self.exp_id = uuid.uuid4()\n",
    "        os.makedirs(f'./{self.exp_id}/checkpoints', exist_ok=True)        \n",
    "\n",
    "        # create running trackers to keep track of time, loss, metrics\n",
    "        self.data_time = Tracker('data_time')   \n",
    "        self.fwd_time = Tracker('fwd_time')\n",
    "        self.criterion_time = Tracker('criterion_time')\n",
    "        self.bkwd_time = Tracker('bkwd_time')\n",
    "        self.batch_time = Tracker('batch_time')\n",
    "        self.loss = Tracker('loss')\n",
    "    \n",
    "        # gather model params to optimize\n",
    "        self.weights, self.biases = list(), list()\n",
    "        for param_name, param in self.m.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if param_name.endswith('.bias'):\n",
    "                    self.biases.append(param)\n",
    "                else:\n",
    "                    self.weights.append(param)\n",
    "        \n",
    "                 \n",
    "    def save_checkpoint(self, epoch, model, optimizer):\n",
    "        state = {'epoch': epoch,\n",
    "                 'model': model,\n",
    "                 'optimizer': optimizer}\n",
    "        filename = f'{self.exp_id}/checkpoints/{self.name}_{epoch}epoch.pth.tar'\n",
    "        torch.save(state, filename)\n",
    "\n",
    "        \n",
    "    def load_checkpoint(self, path):        \n",
    "        chkpt = torch.load(path)\n",
    "        self.epoch = chkpt['epoch'] + 1; print(f\"checkpoint loaded; resume training from epoch {self.epoch}\")\n",
    "        self.m = chkpt['model']\n",
    "        self.optimizer = chkpt['optimizer']\n",
    "    \n",
    "                 \n",
    "    def train_one_epoch(self, epoch):        \n",
    "        start_time = time.time()\n",
    "        # iterate over batches\n",
    "        for i, batch in enumerate(self.dl):\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            # update data time to record how long it takes to load one batch of data\n",
    "            self.data_time(time.time() - start_time)\n",
    "            # get ground truth information\n",
    "            images = batch['images'].to(self.device)\n",
    "            boxes  = [b.to(self.device) for b in batch['boxes']]\n",
    "            labels = [c.to(self.device) for c in batch['cats']]\n",
    "                        \n",
    "            # forward pass to model & track time taken\n",
    "            t = time.time()\n",
    "            pred_boxes, pred_scores = self.m(images)\n",
    "            self.fwd_time(time.time() - t)\n",
    "            \n",
    "            # compute loss & track time taken\n",
    "            t = time.time()\n",
    "            loss = self.criterion(pred_boxes, pred_scores, boxes, labels)\n",
    "            self.criterion_time(time.time() - t)\n",
    "            \n",
    "            # update params\n",
    "            t = time.time()\n",
    "            self.optimizer.zero_grad()\n",
    "            # back-prop\n",
    "            loss.backward()\n",
    "            # clip gradient\n",
    "            if self.gradient_clip is not None:\n",
    "                clip_gradient(self.optimizer, self.gradient_clip)\n",
    "            # update trainable params\n",
    "            self.optimizer.step()\n",
    "            self.bkwd_time(time.time() - t)\n",
    "            \n",
    "            # update trackers\n",
    "            self.loss(loss.item(), images.size(0))\n",
    "            self.batch_time(time.time() - batch_start_time)\n",
    "\n",
    "            # Print status\n",
    "            if self.verbose is not None:\n",
    "                if i % self.verbose == 0:\n",
    "                    print(f\"Epoch: [{epoch}][{i}/{len(self.dl)}]\\t\"\n",
    "                          f\"Batch time: {self.batch_time.val:.3f} ({self.batch_time.avg:.3f})\\t\"\n",
    "                          f\"Loss: {self.loss.val:.4f} ({self.loss.avg:.4f})\"\n",
    "                         )\n",
    "        # free some memory since their histories may be stored\n",
    "        del pred_boxes, pred_scores, images, boxes, labels  \n",
    "\n",
    "                 \n",
    "    def train(self, n_epochs, optimizer, lr, gradient_clip=None, eval_every_n_epoch=1, save_every_n_epoch=1):\n",
    "        # setup experiment\n",
    "        self.optimizer = optimizer\n",
    "        self.lr = lr\n",
    "        self.gradient_clip = gradient_clip\n",
    "        self.save_every_n_epoch = save_every_n_epoch\n",
    "        \n",
    "        # iterate over epochs\n",
    "        for n in range(n_epochs):\n",
    "            # run one epoch training\n",
    "            self.train_one_epoch(n)\n",
    "            # evaluate every n epoch\n",
    "            pass\n",
    "            # save every n epoch\n",
    "            if n % self.save_every_n_epoch == 0:\n",
    "                self.save_checkpoint(n, self.m, self.optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Experiment & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init experiment object\n",
    "exp = Exp(dl, ssd, criterion, \"SSD\", verbose=10, device=device)\n",
    "exp.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define & init optimizer\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.SGD(params=[{'params': exp.biases, 'lr': 2 * lr}, {'params': exp.weights}], # update biases at 2x LR over weights\n",
    "                            lr=lr, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/625]\tBatch time: 1.001 (1.001)\tLoss: 4869.3628 (4869.3628)\n",
      "Epoch: [0][10/625]\tBatch time: 0.305 (0.370)\tLoss: 5265.1289 (4809.3320)\n",
      "Epoch: [0][20/625]\tBatch time: 0.308 (0.340)\tLoss: 4451.3511 (5105.8544)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fcb42dc6364d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train for x epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_clip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-f2aa40068fb7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, optimizer, lr, gradient_clip, eval_every_n_epoch, save_every_n_epoch)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# run one epoch training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;31m# evaluate every n epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-f2aa40068fb7>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# compute loss & track time taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pred_boxes, pred_scores, true_boxes, true_classes)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mobj_label_for_each_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj_idx_for_each_prior\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# for those with overlap < threshold, suppress object as background (i.e. class_label=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mobj_label_for_each_prior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj_overlap_for_each_prior\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# add true object class label allocation for each prior bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal"
     ]
    }
   ],
   "source": [
    "# train for x epochs\n",
    "exp.train(10, optimizer, lr, gradient_clip=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
